apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: content-platform-queue-alerts
  namespace: observability
  labels:
    prometheus: kube-prometheus
    role: alert-rules
    app.kubernetes.io/name: copperiq-monitoring
    app.kubernetes.io/component: alert-rules
spec:
  groups:
    - name: content-platform-queues
      interval: 30s
      rules:
        # Queue filter (Content Platform queues)
        # cp_queue_regex = ^(llm-seo|content-platform-.*)$

        # Backlog thresholds (per queue)
        - alert: N8NRabbitMQQueueBacklog
          expr: |
            sum(rabbitmq_queue_messages{namespace="n8n-dev", queue=~"^(llm-seo|content-platform-.*)$"}) by (namespace, vhost, queue) > 200
          for: 10m
          labels:
            severity: warning
            system: n8n
            component: messaging
            backend: rabbitmq
            service: content-platform
            category: application
          annotations:
            summary: "Dev backlog on queue {{ $labels.queue }}: {{ $value }} messages"
            description: |
              Development environment RabbitMQ queue is growing: {{ $value }} messages queued.
              
              Context: ~7-30 jobs/hour capacity (1 worker, 2-8 min per job)
              
              Possible causes: worker unhealthy, slower jobs, increased activity.
              
              Action:
              1. Check n8n worker health: `kubectl get pods -n n8n-dev -l app=n8n-dev-worker`
              2. Check logs: `kubectl logs -n n8n-dev -l app=n8n-dev-worker --tail=100`
              3. Verify consumers: `kubectl exec -n n8n-dev rabbitmq-0 -- rabbitmqctl list_queues name consumers messages`

        - alert: N8NRabbitMQQueueBacklog
          expr: |
            sum(rabbitmq_queue_messages{namespace="n8n-prod", queue=~"^(llm-seo|content-platform-.*)$"}) by (namespace, vhost, queue) > 500
          for: 10m
          labels:
            severity: warning
            system: n8n
            component: messaging
            backend: rabbitmq
            service: content-platform
            category: application
          annotations:
            summary: "Prod backlog on queue {{ $labels.queue }}: {{ $value }} messages"
            description: |
              Production environment RabbitMQ queue is growing: {{ $value }} messages queued.
              
              Context: ~7-30 jobs/hour capacity (1 worker, 2-8 min per job)
              
              Possible causes: worker unhealthy, slower jobs, increased activity.
              
              Action:
              1. Check n8n worker health: `kubectl get pods -n n8n-prod -l app=n8n-worker`
              2. Check logs: `kubectl logs -n n8n-prod -l app=n8n-worker --tail=100`
              3. Consider scaling workers if sustained
              4. Verify consumers: `kubectl exec -n n8n-prod rabbitmq-0 -- rabbitmqctl list_queues name consumers messages`

        - alert: N8NRabbitMQQueueBacklog
          expr: |
            sum(rabbitmq_queue_messages{namespace="n8n-prod", queue=~"^(llm-seo|content-platform-.*)$"}) by (namespace, vhost, queue) > 1000
          for: 5m
          labels:
            severity: critical
            system: n8n
            component: messaging
            backend: rabbitmq
            service: content-platform
            category: application
          annotations:
            summary: "CRITICAL backlog on queue {{ $labels.queue }}: {{ $value }} messages"
            description: |
              Severe backlog: {{ $value }} messages in production queue.
              
              Immediate action required:
              1. Check consumers: `kubectl exec -n n8n-prod rabbitmq-0 -- rabbitmqctl list_consumers`
              2. Check worker resources: `kubectl top pods -n n8n-prod -l app=n8n-worker`
              3. Check errors: `kubectl logs -n n8n-prod -l app=n8n-worker --tail=500 | grep -i error`
              4. Scale workers: `kubectl scale deployment n8n-worker -n n8n-prod --replicas=3`

        # Stale messages (oldest ready message age)
        - alert: N8NRabbitMQQueueStale
          expr: |
            rabbitmq_queue_messages_ready_max_age_seconds{namespace=~"n8n-(dev|prod)", queue=~"^(llm-seo|content-platform-.*)$"} > 600
          for: 5m
          labels:
            severity: warning
            system: n8n
            component: messaging
            backend: rabbitmq
            service: content-platform
            category: application
          annotations:
            summary: "Queue {{ $labels.queue }} messages aging (>10 min)"
            description: |
              Oldest message in {{ $labels.namespace }} queue is {{ $value | humanizeDuration }} old.
              Expected: 2-8 minutes.

        - alert: N8NRabbitMQQueueStale
          expr: |
            max(rabbitmq_queue_messages_ready_max_age_seconds{namespace=~"n8n-(dev|prod)", queue=~"^(llm-seo|content-platform-.*)$"}) by (namespace, vhost, queue) > 1800
          for: 5m
          labels:
            severity: critical
            system: n8n
            component: messaging
            backend: rabbitmq
            service: content-platform
            category: application
          annotations:
            summary: "Queue {{ $labels.queue }} messages STALE (>30 min)"
            description: |
              Consumers may be stuck or crashed.

        # No consumers
        - alert: N8NRabbitMQQueueNoConsumers
          expr: |
            sum(rabbitmq_queue_consumers{namespace=~"n8n-(dev|prod)", queue=~"^(llm-seo|content-platform-.*)$"}) by (namespace, vhost, queue) == 0
              and sum(rabbitmq_queue_messages{namespace=~"n8n-(dev|prod)", queue=~"^(llm-seo|content-platform-.*)$"}) by (namespace, vhost, queue) > 0
          for: 5m
          labels:
            severity: critical
            system: n8n
            component: messaging
            backend: rabbitmq
            service: content-platform
            category: application
          annotations:
            summary: "Queue {{ $labels.queue }} has no consumers"
            description: |
              Impact: processing stopped.

        # Rate imbalance (publish > ack)
        - alert: N8NRabbitMQQueuePilingUp
          expr: |
            (
              sum(rate(rabbitmq_queue_messages_published_total{namespace=~"n8n-(dev|prod)", queue=~"^(llm-seo|content-platform-.*)$"}[5m])) by (namespace, vhost, queue)
              -
              sum(rate(rabbitmq_queue_messages_ack_total{namespace=~"n8n-(dev|prod)", queue=~"^(llm-seo|content-platform-.*)$"}[5m])) by (namespace, vhost, queue)
            ) > 0.1
          for: 10m
          labels:
            severity: warning
            system: n8n
            component: messaging
            backend: rabbitmq
            service: content-platform
            category: application
          annotations:
            summary: "Queue {{ $labels.queue }} is piling up"
            description: |
              Incoming rate exceeds processing (acks) rate.

        # >5 messages waiting >1 minute
        - alert: N8NRabbitMQQueueWaitingOver1m
          expr: |
            sum(rabbitmq_queue_messages{namespace=~"n8n-(dev|prod)", queue=~"^(llm-seo|content-platform-.*)$"}) by (namespace, vhost, queue) > 5
              and max(rabbitmq_queue_messages_ready_max_age_seconds{namespace=~"n8n-(dev|prod)", queue=~"^(llm-seo|content-platform-.*)$"}) by (namespace, vhost, queue) > 60
          for: 5m
          labels:
            severity: warning
            system: n8n
            component: messaging
            backend: rabbitmq
            service: content-platform
            category: application
          annotations:
            summary: "Queue {{ $labels.queue }} has >5 messages waiting >1 minute"
            description: |
              Early backlog signal.

        # Messages present but acks ~ 0
        - alert: N8NRabbitMQQueueNoProcessing
          expr: |
            sum(rabbitmq_queue_messages{namespace=~"n8n-(dev|prod)", queue=~"^(llm-seo|content-platform-.*)$"}) by (namespace, vhost, queue) > 0
              and sum(rate(rabbitmq_queue_messages_ack_total{namespace=~"n8n-(dev|prod)", queue=~"^(llm-seo|content-platform-.*)$"}[5m])) by (namespace, vhost, queue) <= 0.01
          for: 10m
          labels:
            severity: critical
            system: n8n
            component: messaging
            backend: rabbitmq
            service: content-platform
            category: application
          annotations:
            summary: "Queue {{ $labels.queue }} not processing (acks ~ 0 msg/s)"
            description: |
              Messages present but no acknowledgements for 10 minutes.

        # Drain time > 30 minutes
        - alert: N8NRabbitMQQueueDrainTimeHigh
          expr: |
            sum(rabbitmq_queue_messages{namespace=~"n8n-(dev|prod)", queue=~"^(llm-seo|content-platform-.*)$"}) by (namespace, vhost, queue)
              / clamp_min(sum(rate(rabbitmq_queue_messages_ack_total{namespace=~"n8n-(dev|prod)", queue=~"^(llm-seo|content-platform-.*)$"}[5m])) by (namespace, vhost, queue), 0.01)
              > 1800
          for: 10m
          labels:
            severity: warning
            system: n8n
            component: messaging
            backend: rabbitmq
            service: content-platform
            category: application
          annotations:
            summary: "Queue {{ $labels.queue }} drain time > 30 minutes"
            description: |
              Estimated drain time exceeds 30 minutes at current ack rate.
            runbook_url: "https://github.com/Copper-IQ/copperiq-monitoring/blob/main/docs/runbooks/content-platform-queue-backlog.md"

- alert: N8NContentQueueNoProcessing
          expr: |
            sum(rabbitmq_queue_messages{namespace=~"n8n-(dev|prod)"}) by (namespace, vhost, queue) > 0
            and
            sum(rate(rabbitmq_queue_messages_ack_total{namespace=~"n8n-(dev|prod)"}[5m])) by (namespace, vhost, queue) <= 0.01
          for: 10m
          labels:
            severity: critical
            component: content-platform
            category: application
          annotations:
            summary: "Queue {{ $labels.queue }} not processing (acks ~ 0 msg/s)"
            description: |
              Queue {{ $labels.queue }} in {{ $labels.namespace }} has messages but no acknowledgements for 10 minutes.
              
              **Impact**: Processing stalled.
              **Action**:
              1. Verify consumers: `kubectl exec -n {{ $labels.namespace }} rabbitmq-0 -- rabbitmqctl list_queues name consumers`
              2. Check worker logs for errors: `kubectl logs -n {{ $labels.namespace }} -l app contains worker --tail=200`
              3. Restart workers if needed.
            runbook_url: "https://github.com/Copper-IQ/copperiq-monitoring/blob/main/docs/runbooks/content-platform-queue-backlog.md"

- alert: N8NContentQueueDrainTimeHigh
          expr: |
            sum(rabbitmq_queue_messages{namespace=~"n8n-(dev|prod)"}) by (namespace, vhost, queue)
              /
            clamp_min(sum(rate(rabbitmq_queue_messages_ack_total{namespace=~"n8n-(dev|prod)"}[5m])) by (namespace, vhost, queue), 0.01)
              > 1800
          for: 10m
          labels:
            severity: warning
            component: content-platform
            category: application
          annotations:
            summary: "Queue {{ $labels.queue }} drain time > 30 minutes"
            description: |
              Estimated time to drain queue {{ $labels.queue }} in {{ $labels.namespace }} exceeds 30 minutes based on current ack rate.
              
              **Formula**: messages / ack_rate over 5m window
              **Action**:
              1. Consider scaling workers or reducing publish rate.
              2. Investigate slow jobs in n8n.
            runbook_url: "https://github.com/Copper-IQ/copperiq-monitoring/blob/main/docs/runbooks/content-platform-queue-backlog.md"
