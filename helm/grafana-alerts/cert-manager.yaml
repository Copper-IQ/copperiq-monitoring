# Grafana Unified Alerting Rules: cert-manager
# Converted from PrometheusRule: cert-manager-alerts
apiVersion: 1
groups:
  - orgId: 1
    name: cert-manager
    folder: applications
    interval: 1m
    rules:
      # REMOVED: CertificateExpiringSoon and CertificateExpiringCritical
      # Reason: Cert-manager auto-renews ~30 days before expiry.
      # If we're alerting at 7 days, renewal has already been failing for 23 days.
      # The CertificateNotReady alert (below) catches renewal failures immediately.
      # Time-based expiry alerts are redundant and create alert fatigue.
      - uid: certificatenotready
        title: CertificateNotReady
        condition: C
        for: 10m  # Reduced from 30m - we want to know about renewal failures quickly
        noDataState: OK
        execErrState: Alerting
        annotations:
          summary: Certificate {{ $labels.name }} is not ready
          description: >
            Certificate {{ $labels.name }} in namespace {{ $labels.namespace }} has been in NotReady state for 30
            minutes.


            **Impact**: New or renewed certificate not available, service may be inaccessible.


            **Action**:

            1. Describe certificate: `kubectl describe certificate {{ $labels.name }} -n {{ $labels.namespace }}`

            2. Check certificate request: `kubectl describe certificaterequest -n {{ $labels.namespace }}`

            3. Check ACME orders: `kubectl describe order -n {{ $labels.namespace }}`

            4. Check DNS challenge if DNS-01: `kubectl get challenges -n {{ $labels.namespace }}`

            5. Check cert-manager controller logs: `kubectl logs -n cert-manager -l app=cert-manager`
        labels:
          severity: critical
          component: cert-manager
          category: platform
        data:
          - refId: A
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: prometheus
            model:
              expr: |
                min by (name, exported_namespace) (
                  certmanager_certificate_ready_status{condition="False"}
                )
              refId: A
              datasource:
                type: prometheus
                uid: prometheus
              intervalMs: 1000
              maxDataPoints: 43200
          - refId: B
            relativeTimeRange:
              from: 0
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
              datasource:
                type: __expr__
                uid: __expr__
          - refId: C
            relativeTimeRange:
              from: 0
              to: 0
            datasourceUid: __expr__
            model:
              type: math
              expression: $B > 0
              refId: C
              datasource:
                type: __expr__
                uid: __expr__
      - uid: certmanagerdown
        title: CertManagerDown
        condition: C
        for: 5m
        noDataState: OK
        execErrState: Alerting
        annotations:
          summary: Cert-manager controller is down
          description: |
            Cert-manager controller is not responding.

            **Impact**:
            - Certificate renewals stopped
            - New certificates cannot be issued
            - Certificate expiry risk

            **Action**:
            1. Check cert-manager pods: `kubectl get pods -n cert-manager`
            2. Check pod logs: `kubectl logs -n cert-manager -l app=cert-manager --tail=200`
            3. Check pod events: `kubectl get events -n cert-manager --sort-by='.lastTimestamp'`
            4. Restart if needed: `kubectl rollout restart deployment -n cert-manager cert-manager`
        labels:
          severity: critical
          component: cert-manager
          category: platform
        data:
          - refId: A
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: prometheus
            model:
              expr: up{job="cert-manager"}
              refId: A
              datasource:
                type: prometheus
                uid: prometheus
              intervalMs: 1000
              maxDataPoints: 43200
          - refId: B
            relativeTimeRange:
              from: 0
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
              datasource:
                type: __expr__
                uid: __expr__
          - refId: C
            relativeTimeRange:
              from: 0
              to: 0
            datasourceUid: __expr__
            model:
              type: math
              expression: $B == 0
              refId: C
              datasource:
                type: __expr__
                uid: __expr__
      - uid: acmechallengesfailing
        title: ACMEChallengesFailing
        condition: C
        for: 10m
        noDataState: OK
        execErrState: Alerting
        annotations:
          summary: ACME challenges are failing
          description: |
            Multiple ACME challenge requests are failing.

            **Failed requests**: {{ $value }} in the last 10 minutes

            **Possible causes**:
            1. DNS not propagated (DNS-01 challenge)
            2. Ingress not accessible (HTTP-01 challenge)
            3. Let's Encrypt rate limits
            4. Network connectivity issues

            **Action**:
            1. Check challenges: `kubectl get challenges --all-namespaces`
            2. Describe failing challenges: `kubectl describe challenge -n <namespace>`
            3. For DNS-01: Verify external-dns is working
            4. For HTTP-01: Verify ingress is accessible
            5. Check Let's Encrypt status: https://letsencrypt.status.io/
        labels:
          severity: warning
          component: cert-manager
          category: platform
        data:
          - refId: A
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: prometheus
            model:
              expr: increase(certmanager_http_acme_client_request_count{status=~"4..|5.."}[10m])
              refId: A
              datasource:
                type: prometheus
                uid: prometheus
              intervalMs: 1000
              maxDataPoints: 43200
          - refId: B
            relativeTimeRange:
              from: 0
              to: 0
            datasourceUid: __expr__
            model:
              type: reduce
              expression: A
              reducer: last
              refId: B
              datasource:
                type: __expr__
                uid: __expr__
          - refId: C
            relativeTimeRange:
              from: 0
              to: 0
            datasourceUid: __expr__
            model:
              type: math
              expression: $B > 5
              refId: C
              datasource:
                type: __expr__
                uid: __expr__
